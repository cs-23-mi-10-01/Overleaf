\section{Related Work}
\label{sec:related-work}

This paper is a continuation of \cite{P9}, where different embedding methods are analyzed through an exploration of the quality of results when the models make link predictions. The main observation made from that analysis is that the most influential contributing factor that influence the quality of the results is the relations and the structure of the knowledge graph that surrounds them. This is the reasoning for what this paper concerns, and this paper serves to further examine the structure of the knowledge graph surrounding the relations, increase reliability of the findings from the previous paper, and find other contributing factors that can influence the quality of the results.

As this paper is a direct continuation of \cite{P9}, the related work of that paper is also applicable here, and it covers the different categories of temporal knowledge graph embedding methods, namely transformation, tensor decomposition, and neural network. Transformational methods use geometric functions to score facts in the embedding. Tensor decomposition methods use tensor and eigenvector products to decompose tensors into low-dimentional representations that is used to score the facts. Neural networks use a number of learned layers to score facts based on the numerical representation of the elements of the facts. Out of these three categories, neural network methods seem to have fallen out of favour. Not many recent temporal neural network methods exist, and those that are available lack a sufficient quality in their implementation and documentation to reproduce their results. Influential transformational methods include RotatE \cite{sun2019rotate}, TeRo \cite{xu2020tero}, and ChronoR \cite{sadeighan2021chronor}. Influential tensor decomposition methods include TNTComplEx \cite{lacroix2020tcomplex}, TimePlex \cite{jain2020timeplex}, and ATiSE \cite{xu19atise}. Influential neural network methods include TFLEX \cite{lin22tflex} and Re-Net \cite{jin2019renet}. For more examples of methods in these categores, see the previous paper.

Diachronic embedding is an embedding method that takes an existing non-temporal embedding method and modifies it, such that temporal information is included in the entity embeddings, as described in \cite{goel19diachronicemb}. 

Temporal accuracy metrics has previously been defined for scoring functions using a reciprocal measure of sets of timestamps \cite{surdeanu2013overviewtac}, and using bounding boxes to evaluate the intersections and hulls between intervals \cite{jain2020timeplex}. These metrics are mostly made for scoring functions and not statistical evaluation of time predictions, as they represent the scores as a non-human readable measure, and it is difficult to interpret if the results are usable in a question answering context from these metrics alone.

Relation properties in knowledge graphs have been defined in non-temporal contexts as symmetry, anti-symmetry, reflexivity, and inversion \cite{schmidt10relationalmathematics}. These properties define the structure of the knowledge graph surrounding the relation, and some methods are incompatible with some of these properties (for example transformations cannot model symmetry \cite{chami2020atth}, while pairwise products of embedding vectors cannot model anti-symmetry or inverse relations \cite{gregucci23sepa}). Previous research in temporal knowledge graph fact prediction do not consider the underlying structure of the graph, potentially because the temporal knowledge graphs are incomplete, and therefore the structures have not been defined as rigidly as they have for non-temporal knowledge graphs.


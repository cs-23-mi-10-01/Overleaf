\subsection{Joint Timestamp Selection}
\label{seubsec:timestamp_voting_experiment}

\input{content/hypothesis_evaluation/tables/timestamp_voting/timestamp_voting_table}
\input{content/hypothesis_evaluation/tables/relation_properties_folder/relation_diff}
To evaulate \autoref{hyp:timestamp_voting}, the models are compared using the \gls{mae} score achieved when predicting timestamp. The scores are also compared to the \gls{mae} score of predictions achieved when all models jointly select a timestamp answer. The results of this evaluation can be seen in \autoref{tab:timestamp_voting_table}. Error distributions of the individual methods can be found in \autoref{time_prediction_error_distribution}.

The results show that the \gls{mae} score is lower in predictions on ICEWS when jointly selecting the answer timestamp. An average error of 90+ days is very high in ICEWS, as this dataset only spans a year. The average error of 3 months means the average error range is 6 months, which is half of the dataset.
%as that dataset only spans a year, this means that an average error of 90 days results in an average error range of six months.
%as the number of possible timestamp answers in this dataset is 365, and the \gls{mae} scores are higher than 90 days, indicating that the average result is within half of the dataset. 
For TeRo, ATiSE and TimePlex, the result indicates that the predicted timestamp is random, which is supported by their error distribution in the appendix. Joint timestamp selection seems to average out wrong answers in both directions for each method, and thereby achieves a higher score, supporting the claim of \autoref{hyp:timestamp_voting}. 

On WikiData, the precision is highest on TimePlex, and the difference between the \gls{mae} of the most precise model and the least precise model DE-TransE is very high at \textasciitilde1000 years. The results on WikiData indicate that this dataset is difficult for the DE models to make time predictions on, and the \gls{mae} score of these three models seem to indicate that the predicted answer is random, which is again supported by the error distribution in the appendix. Joint selection achieves a score that is in the middle between the two extremes, and as it is calculated by the mean average, the DE models make the results significantly worse. 
%, indicating that the DE models might make the joint timestamp selection approach worse. 

For YAGO the same pattern as WikiData emerges. However TimePlex is significantly worse on this dataset and ATiSE has the best score when comparing the closest timestamp in its time span. The joint time prediction is once again impaired by the worst models as it is a mean average. 
%The most precise model on average is also TimePlex, followed by ATiSE and then joint selection close thereafter, however ATiSE has the best score when comparing the closest timestamp in its time span. 
%The \gls{mae} score of the joint timestamp selection falls in between the best and the worst score of the base models, indicating that it is positively influenced by models with good performance, and negatively influenced by models with bad performance.

When TeRo and ATiSE make time predictions, they attempt to predict both the beginning and end timestamp of the query, resulting in a time interval prediction. When contributing to the joint timestamp selection, a timestamp in the middle of the time interval is used instead.

The results show that the overall error of time predictions is high. The best \gls{mae} result on \mbox{ICEWS} is $84.71$ days, which is an unacceptable average error in a \gls{qa} context, as the purpose of queries on ICEWS is to make early predictions on critical events like military operations or civilian unrest. These need to be highly accurate to be useful. Similarly, having an average error of $94+$ years on YAGO is unacceptable, as queries like birth dates and war periods need to be somewhat precise to be useful. On the other hand, TimePlex achieves an \gls{mae} score of $21.90$, which is accurate enough to be useful in some contexts that do not require high accuracy, e.g. when asking about when technological ages like the industrial age began and ended. TimePlex is the only examined model that attempts to optimize timestamp predictions, and as such it is encouraging that it achieves the only useful result, but it still only achieves it on one of the three examined datasets.

Overall, this indicates that \textbf{\autoref{hyp:timestamp_voting} is true} in some situations, which means that sometimes the most precise results are found with mean average depending on the quality of predictions of base models. 
%Our results indicate that joint selection of timestamp predictions can improve results if the predictions made by the base models are inaccurate, or if they all achieve a similar \gls{mae} score. 
A more complex voting mechanism when jointly selecting timestamps might yield better results, such as giving less weight to less accurate models, or using more than just the top scoring prediction for each model.


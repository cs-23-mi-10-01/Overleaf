\subsection{Joint Timestamp Selection}
\label{seubsec:timestamp_voting_experiment}

Hypothesis \autoref{hyp:timestamp_voting} concerns making time predictions by using the average of the best prediction of several models.

\input{content/hypothesis_evaluation/tables/timestamp_voting/timestamp_voting_table}

To evaulate this, the models are compared using the \gls{mae} score achieved when making time predictions. The \gls{mae} is in days for ICEWS, and years for WikiData and YAGO. The scores are also compared to the \gls{mae} score of predictions achieved when all models jointly select a timestamp answer. The results of this evaluation can be seen in \autoref{tab:timestamp_voting_table}. Error distributions of the individual methods can be found in \autoref{time_prediction_error_distribution}.

When TeRo and ATiSE make time predictions, they attempt to predict both the beginning and end timestamp of the query, resulting in a time interval prediction. When contributing to the joint timestamp selection, a timestamp in the middle of the time interval is used instead.

The results show that the \gls{mae} score is lower in predictions on ICEWS when jointly selecting the answer timestamp.
An average error of 90+ days is very high in ICEWS, as this dataset only spans a year. This means the average error range is 6 months, which is half of the dataset.
For TeRo, ATiSE and TimePlex, the result indicates that the predicted timestamp is random, which is supported by their error distribution in \autoref{time_prediction_error_distribution}. Joint timestamp selection seems to average out wrong answers in both directions for each method, and thereby achieves a higher score, supporting \autoref{hyp:timestamp_voting}. 

On WikiData TimePlex has the highest precision, and the difference between the \gls{mae} of the most precise model and the least precise model DE-TransE is very high at \textasciitilde1000 years. The results on WikiData indicate that this dataset is difficult for the DE models to make time predictions on, and the \gls{mae} scores of these three models seem to indicate that the predicted answer is random, which is again supported by the error distribution in \autoref{time_prediction_error_distribution}. Joint selection achieves a score that is in the middle between the two extremes, and as it is decided using the mean average of the time predictions of all contributing models, the DE models make the results significantly worse. 

For YAGO the same pattern as WikiData emerges. However TimePlex is significantly worse on this dataset and ATiSE has the best score when comparing the closest timestamp in its time span. The joint time prediction is once again impaired by the worst models. 

The results show that the overall error of time predictions is high. The best \gls{mae} result on \mbox{ICEWS} is $84.71$ days, which is an unacceptable average error in a \gls{qa} context, as the purpose of queries on ICEWS is to make early predictions on critical events like military operations or civilian unrest. These need to be highly accurate to be useful. Similarly, having an average error of $94+$ years on YAGO is unacceptable, as queries like birth dates and war periods need to be somewhat precise to be useful. On the other hand, TimePlex achieves an \gls{mae} score of $21.90$, which is accurate enough to be useful in some contexts that do not require high accuracy, e.g. when asking about when technological ages like the industrial age began and ended. TimePlex is the only examined model that attempts to optimize time predictions, and as such it is encouraging that it achieves the only useful result, but it still only achieves it on one of the three examined datasets.

Overall, this indicates that \textbf{\autoref{hyp:timestamp_voting} is true} if the base models have approximately equal precision.
A more complex voting mechanism when jointly selecting timestamps might yield better results, such as giving less weight to less accurate models, or using more than just the top scoring prediction for each model.